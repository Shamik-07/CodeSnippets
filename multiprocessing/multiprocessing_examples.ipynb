{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing with Multiprocessing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cpu_bound(number):\n",
    "#     # print(multiprocessing.current_process().name)\n",
    "#     return sum(i * i for i in range(number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sums(numbers):\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        result = pool.map(cpu_bound, numbers)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [5_000_000 + x for x in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration 9.166558523022104 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "find_sums(numbers)\n",
    "duration = time.perf_counter() - start_time\n",
    "print(f\"Duration {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above works as long as there are no errors. There's no possibility of including a try-except block and process the numbers that can be processed. Below is the solution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_w_str = numbers[:] + ['str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sums(numbers):\n",
    "    result = []\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        async_results = [pool.apply_async(cpu_bound, (number,)) for number in numbers]\n",
    "        for async_result in async_results:\n",
    "            try:\n",
    "                result.append(async_result.get())\n",
    "            except Exception:\n",
    "            # except Exception as e:\n",
    "                # print(f\"An error occurred: {e}\")\n",
    "                pass\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration 9.166558523022104 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "find_sums(numbers_w_str)\n",
    "duration = time.perf_counter() - start_time\n",
    "print(f\"Duration {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing with concurrent.futures library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The below returns a generator object with the results. Once the generator has been iterated over, it becomes None.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration 9.324354574957397 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    result = executor.map(cpu_bound, numbers)\n",
    "print(f\"Duration {time.perf_counter()-start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Despite the try/except block, the loop doesn't execute completely. This the problem with map is that if there's any error, the entire execution will stop.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_w_str = numbers[:] + ['str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 41666654166667500000\n",
      "Result: 41666679166667500000\n",
      "Result: 41666704166677500001\n",
      "Result: 41666729166697500005\n",
      "Result: 41666754166727500014\n",
      "Result: 41666779166767500030\n",
      "Result: 41666804166817500055\n",
      "Result: 41666829166877500091\n",
      "Result: 41666854166947500140\n",
      "Result: 41666879167027500204\n",
      "Result: 41666904167117500285\n",
      "Result: 41666929167217500385\n",
      "Result: 41666954167327500506\n",
      "Result: 41666979167447500650\n",
      "Result: 41667004167577500819\n",
      "Result: 41667029167717501015\n",
      "Result: 41667054167867501240\n",
      "Result: 41667079168027501496\n",
      "Result: 41667104168197501785\n",
      "Result: 41667129168377502109\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'str' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/shamik/miniconda3/envs/py38/lib/python3.8/concurrent/futures/process.py\", line 239, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/home/shamik/miniconda3/envs/py38/lib/python3.8/concurrent/futures/process.py\", line 198, in _process_chunk\n    return [fn(*args) for args in chunk]\n  File \"/home/shamik/miniconda3/envs/py38/lib/python3.8/concurrent/futures/process.py\", line 198, in <listcomp>\n    return [fn(*args) for args in chunk]\n  File \"/tmp/ipykernel_257567/144979005.py\", line 7, in cpu_bound\n    return sum(i * i for i in range(number))\nTypeError: 'str' object cannot be interpreted as an integer\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:3\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/concurrent/futures/process.py:484\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;124;03m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;124;03m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    485\u001b[0m         element\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    486\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m element:\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mresult(end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/concurrent/futures/_base.py:437\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "with ProcessPoolExecutor() as executor:\n",
    "    r = executor.map(cpu_bound, numbers)\n",
    "    for i,j in enumerate(r):\n",
    "        try:\n",
    "            print(f\"Result: {j}\")\n",
    "        except Exception:\n",
    "            print(f\"Can't process result for: {numbers[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To execute the entire loop the same needs to be run with `executor.submit` instead.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 41667104168197501785\n",
      "Result: 41666754166727500014\n",
      "Result: 41666854166947500140\n",
      "Result: 41667079168027501496\n",
      "Result: 41666654166667500000\n",
      "Result: 41667129168377502109\n",
      "Result: 41666779166767500030\n",
      "Result: 41667029167717501015\n",
      "Result: 41666954167327500506\n",
      "Result: 41667054167867501240\n",
      "Result: 41666929167217500385\n",
      "Result: 41666679166667500000\n",
      "Result: 41666804166817500055\n",
      "Result: 41666879167027500204\n",
      "Result: 41666704166677500001\n",
      "Result: 41667004167577500819\n",
      "Result: 41666979167447500650\n",
      "Result: 41666904167117500285\n",
      "Result: 41666729166697500005\n",
      "Result: 41666829166877500091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['str']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with ProcessPoolExecutor() as executor:\n",
    "    r = [executor.submit(cpu_bound, num) for num in numbers]\n",
    "for i in (as_completed(r)):\n",
    "    try:\n",
    "        print(f\"Result: {i.result()}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "[f\"The number for which it can't be processed: {j}\" for i,j in zip(r,numbers) if i.exception()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing with multiple function arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(input_path, output_path, size=(512,512)):\n",
    "    ...\n",
    "    \n",
    "images, output_paths, sizes = zip(*[(image, output_dir/f\"{image.stem}.{image.suffix}\", (512, 512))\n",
    "                                    for image in image_dir.iterdir()])\n",
    "# the resize_image function does take in multiple arguments as iterables in the executor object\n",
    "# the same can be done with apply too\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    futures = [executor.submit(resize_image, image, output_path, size)\n",
    "               for image, output_path, size in zip(images, output_paths, sizes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This can be done with the apply_async of multiprocessing too.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(input_path, output_path, size=(512,512)):\n",
    "    ...\n",
    "    \n",
    "images, output_paths, sizes = zip(*[(image, output_dir/f\"{image.stem}.{image.suffix}\", (512, 512))\n",
    "                                    for image in image_dir.iterdir()])\n",
    "\n",
    "with multiprocessing.Pool() as pool:\n",
    "        async_results = [pool.apply_async(resize_image, (image, output_path, size))\n",
    "                         for image, output_path, size in zip(images, output_paths, sizes)]\n",
    "    #     for async_result in async_results:\n",
    "    #         try:\n",
    "    #             result.append(async_result.get())\n",
    "    #         except Exception:\n",
    "    #         # except Exception as e:\n",
    "    #             # print(f\"An error occurred: {e}\")\n",
    "    #             pass\n",
    "    # return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing for Pandas Apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Multiprocessing Standard library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Callable\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def parallel_apply(\n",
    "        df_or_s: Union[pd.DataFrame, pd.Series],\n",
    "        func: Callable,\n",
    "        desc: str,\n",
    "        n_jobs: int = mp.cpu_count()-1,\n",
    "        progress_bar: bool = True\n",
    "    ) -> Union[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"A method to use multiprocessing for `df.apply()` or `s.apply()`.\n",
    "\n",
    "    Args:\n",
    "        df_or_s (Union[pd.DataFrame, pd.Series]): Dataframe or series to\n",
    "        use `df.apply()` or `s.apply()` on.\n",
    "        func (Callable): The apply function to be used in\n",
    "        `df.apply()` or `s.apply()`.\n",
    "        n_jobs (int, optional): Number of processors to use.\n",
    "        Defaults to mp.cpu_count()-1.\n",
    "        progress_bar (bool, optional): A tqdm progress bar.\n",
    "        Defaults to True.\n",
    "        desc (str): TQDM description kwarg.\n",
    "\n",
    "    Returns:\n",
    "        Union[pd.DataFrame, pd.Series]: Returns the original dataframe or\n",
    "        series after applying the `df.apply()` or `s.apply()`.\n",
    "    \"\"\"\n",
    "    with mp.Pool(n_jobs) as pool:\n",
    "        split = np.array_split(df_or_s, n_jobs * 2)\n",
    "        if progress_bar is True:\n",
    "            split = tqdm(split, desc=desc)\n",
    "        ret_list = pool.map(func, split)\n",
    "        output_df_or_s = pd.concat(ret_list)\n",
    "    \n",
    "    return output_df_or_s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Joblib library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Callable\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def parallel_apply(\n",
    "        df_or_s: Union[pd.DataFrame, pd.Series],\n",
    "        func: Callable,\n",
    "        desc: str,\n",
    "        n_jobs: int = joblib.cpu_count()-1,\n",
    "        progress_bar: bool = True\n",
    "    ) -> Union[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"A method to use multiprocessing for `df.apply()` or `s.apply()`.\n",
    "\n",
    "    Args:\n",
    "        df_or_s (Union[pd.DataFrame, pd.Series]): Dataframe or series to\n",
    "        use `df.apply()` or `s.apply()` on.\n",
    "        func (Callable): The apply function to be used in\n",
    "        `df.apply()` or `s.apply()`.\n",
    "        n_jobs (int, optional): Number of processors to use.\n",
    "        Defaults to mp.cpu_count()-1.\n",
    "        progress_bar (bool, optional): A tqdm progress bar.\n",
    "        Defaults to True.\n",
    "        desc (str): TQDM description kwarg.\n",
    "\n",
    "    Returns:\n",
    "        Union[pd.DataFrame, pd.Series]: Returns the original dataframe or\n",
    "        series after applying the `df.apply()` or `s.apply()`.\n",
    "    \"\"\"\n",
    "\n",
    "    with Parallel(n_jobs=n_jobs, mmap_mode=\"r+\") as parallel:\n",
    "        split = np.array_split(df_or_s, 2 * n_jobs)\n",
    "        if progress_bar is True:\n",
    "            ret_list = parallel(\n",
    "                delayed(func)(x) for x in tqdm(split, desc=desc))\n",
    "        else:\n",
    "            ret_list = parallel(delayed(func)(x) for x in split)\n",
    "        output_df_or_s = pd.concat(ret_list)\n",
    "\n",
    "    return output_df_or_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a26bff658f397c03e7a6d50107f9eb6f30b6be739d1dd4be66c4365d73d3fda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
